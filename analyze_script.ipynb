{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask import request\n",
    "\n",
    "import requests\n",
    "\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from Levenshtein import distance\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from flask import Flask\n",
    "\n",
    "from sqlalchemy.ext.declarative import DeclarativeMeta\n",
    "import json\n",
    "\n",
    "class AlchemyEncoder(json.JSONEncoder):\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj.__class__, DeclarativeMeta):\n",
    "            # an SQLAlchemy class\n",
    "            fields = {}\n",
    "            for field in [x for x in dir(obj) if not x.startswith('_') and x != 'metadata']:\n",
    "                data = obj.__getattribute__(field)\n",
    "                try:\n",
    "                    json.dumps(data) # this will fail on non-encodable values, like other classes\n",
    "                    fields[field] = data\n",
    "                except TypeError:\n",
    "                    fields[field] = None\n",
    "            # a json-encodable dict\n",
    "            return fields\n",
    "\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///for_docker/api/test_certs.db'\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "db = SQLAlchemy(app)\n",
    "\n",
    "class Сertificate(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    cluster_id = db.Column(db.Integer)\n",
    "    image_url = db.Column(db.String(255))\n",
    "    text_from_image = db.Column(db.Text)\n",
    "    bbs = db.Column(db.JSON)\n",
    "    text_blocks = db.Column(db.JSON)\n",
    "    user_id = db.Column(db.Integer)\n",
    "    post_id = db.Column(db.Integer)\n",
    "    session_id = db.Column(db.Integer, default=-1)\n",
    "\n",
    "    __fulltext_columns__ = ('text_from_image')\n",
    "\n",
    "\n",
    "class Session_has_certs(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    id_session = db.Column(db.Integer)\n",
    "    id_certificate = db.Column(db.Integer)\n",
    "    __table_args__ = (db.UniqueConstraint('id_session', 'id_certificate', name='_session_certificate_uc'),)\n",
    "\n",
    "\n",
    "class Cluster(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    bbs = db.Column(db.JSON)\n",
    "    cluster_name = db.Column(db.String(100))\n",
    "\n",
    "\n",
    "class Session(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    session_name = db.Column(db.String(100))\n",
    "    status = db.Column(db.String(100))\n",
    "    data = db.Column(db.JSON)\n",
    "\n",
    "\n",
    "class Users(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    token = db.Column(db.String(200))\n",
    "    vk_id = db.Column(db.String(100))\n",
    "    \n",
    "db.create_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy_fulltext import FullText, FullTextSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = [file_name.split('.')[0] for file_name in os.listdir('saved_data')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(Сertificate.query.all())\n",
    "print(Cluster.query.all())\n",
    "print(Session.query.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = Сertificate.query.all()\n",
    "json.loads(json.dumps(items, cls=AlchemyEncoder))[0]['text_from_image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask_whooshalchemy\n",
    "Сertificate.query.filter(FullTextSearch('text_from_image', Сertificate)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "headers = {'Content-type': 'application/json',\n",
    "            'Accept': 'text/plain',\n",
    "            'Content-Encoding': 'utf-8'}\n",
    "data = {'ids': user_ids[:10], 'session_name': 'session_server_test_01'}\n",
    "\n",
    "requests.post('http://80.89.204.142:14289/api/analyze', data=json.dumps(data), headers=headers).text#.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.get('http://80.89.204.142:14289/api/get_status').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = requests.get('http://80.89.204.142:14289/api/get_all_clusters').json()['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def download_image(image_url):\n",
    "    res = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(res.content))\n",
    "    return image\n",
    "\n",
    "cluster_ind = 0\n",
    "\n",
    "max_posts_in_cluster = max([len(current_cluster['certificates']) for current_cluster in clusters])\n",
    "\n",
    "fig, axis = plt.subplots(len(clusters), max_posts_in_cluster, figsize=(10, 10*((len(clusters)//max_posts_in_cluster)+1)))\n",
    "\n",
    "for i in range(len(clusters)):\n",
    "    for j in range(len(clusters[i]['certificates'])):\n",
    "        img_url = clusters[i]['certificates'][j]['image_url']\n",
    "        img = download_image(img_url)\n",
    "        \n",
    "        axis[i][j].imshow(img)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('test_res.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "def writeWordToDict(word, my_dict, id, cluster_id):\n",
    "    _end = '_end_'\n",
    "    root = my_dict\n",
    "    #print(root)\n",
    "    for letter in word.lower():\n",
    "        my_dict = my_dict.setdefault(letter, {})\n",
    "    #print(dict)\n",
    "    value = {\"certificate_id\": id, \"cluster_id\": cluster_id}\n",
    "    if my_dict.get(_end) is None:\n",
    "        my_dict[_end] = [] \n",
    "    if not(value in my_dict[_end]):\n",
    "        my_dict[_end].append(value)    \n",
    "    return root\n",
    "\n",
    "def search(tree, word):\n",
    "    _end = '_end_'\n",
    "    current_dict = tree\n",
    "    for letter in word.lower():\n",
    "        if letter not in current_dict:\n",
    "            return False\n",
    "        current_dict = current_dict[letter]\n",
    "    return current_dict[_end]\n",
    "\n",
    "def prepare(clusters):\n",
    "    tree = {}\n",
    "    for cluster in clusters:\n",
    "        certificates = cluster.get('certificates')\n",
    "        cluster_id = cluster.get('cluster_id')\n",
    "        for item in certificates:\n",
    "            id = item.get('id')\n",
    "            bbs = item.get('bbs')\n",
    "            for bb in bbs:\n",
    "                text = bb.get('text')\n",
    "                tree = writeWordToDict(text, tree, id, cluster_id)\n",
    "    return tree\n",
    "\n",
    "\n",
    "tree = prepare(data)\n",
    "search(trie, 'обучение')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "root = my_dict\n",
    "for letter in 'абв'.lower():\n",
    "    my_dict = my_dict.setdefault(letter, {})\n",
    "\n",
    "for letter in 'абг'.lower():\n",
    "    my_dict = my_dict.setdefault(letter, {})\n",
    "\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'a': 1}\n",
    "\n",
    "my_dict.setdefault('a', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_from_queue():\n",
    "    items = Session.query.filter_by(status='in_queue').first()\n",
    "    try:\n",
    "        session_id = json.loads(json.dumps(items, cls=AlchemyEncoder))['id']\n",
    "        ids = json.loads(json.dumps(items, cls=AlchemyEncoder))['data']\n",
    "\n",
    "        return {'session_id': session_id, 'ids': ids}\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def update_status(session_id, new_status):\n",
    "    admin = Session.query.filter_by(id=session_id).first()\n",
    "    admin.status = new_status\n",
    "    db.session.commit()\n",
    "\n",
    "update_status(1, 'in_queue')\n",
    "id_from_queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = Session.query.all()\n",
    "json.loads(json.dumps(items, cls=AlchemyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = Session.query.all()\n",
    "session_id = json.loads(json.dumps(items, cls=AlchemyEncoder))[0]['id']\n",
    "\n",
    "Session.query.filter_by(id=session_id).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vk_api(method, data):\n",
    "    access_token = '25527794e79a323559f47c29b1df2c3b6f1eb91d1f818a6c02867d4bf12c57fb7a8e3dc6830bc046ba482'\n",
    "    version = '5.37'\n",
    "\n",
    "    link = \"https://api.vk.com/method/{}?access_token={}&v={}\".format(method, access_token, version)\n",
    "    for key, val in data.items():\n",
    "        link += '&{}={}'.format(key, str(val))\n",
    "        \n",
    "    res = requests.get(link)\n",
    "    return res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vk_api('users.get', {'user_ids': 'lyangasov_ivan'})['response'][0]['id'])\n",
    "print(vk_api('groups.getById', {'group_id': 'tproger'})['response'][0]['id'])\n",
    "\n",
    "print(vk_api('users.get', {'user_ids': 'tproger'})['error']['error_msg'])\n",
    "print(vk_api('groups.getById', {'group_id': 'lyangasov_ivan'})['error']['error_msg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'tt'.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# находим id всех пользователей\n",
    "\n",
    "def get_all_members(group_id):\n",
    "    \n",
    "    if '/' in group_id:\n",
    "        group_id = group_id.split('/')[-1]\n",
    "        \n",
    "    members = []\n",
    "    old_members = [0] * 1000\n",
    "    i = 0\n",
    "\n",
    "    while len(old_members) == 1000:\n",
    "        data = {'group_id': group_id,\n",
    "                'offset': i * 1000,\n",
    "                'count': 1000}\n",
    "        old_members = vk_api('groups.getMembers', data)['response']['items']\n",
    "        i += 1\n",
    "        members += old_members\n",
    "\n",
    "    return members\n",
    "\n",
    "users_ids = get_all_members('pumptraffic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ids = [file_name.split('.')[0] for file_name in os.listdir('saved_data')]\n",
    "len(users_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ids = users_ids[8:10]\n",
    "res = requests.post('http://0.0.0.0:81/analyze', json={'ids': my_ids, 'session_name': 'тест_3'})\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get('http://0.0.0.0:81/get_all_clusters')\n",
    "print(len(res.json()))\n",
    "\n",
    "'''for cluster in res.json():\n",
    "    print(len(cluster['certificates']))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster.query.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# находим все сертификаты одного пользователя\n",
    "\n",
    "target_words = ['диплом', \n",
    "                'сертификат', \n",
    "                'лицензия', \n",
    "                'certified', \n",
    "                'specialist', \n",
    "                'специалист', \n",
    "                'эксперт']\n",
    "\n",
    "def download_image(image_url):\n",
    "    res = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(res.content))\n",
    "    return image\n",
    "\n",
    "def images_from_res(res):\n",
    "    images_paths = []\n",
    "    for index, item in enumerate(res):\n",
    "        try:\n",
    "            attachments = item['attachments']\n",
    "\n",
    "            for attachment in attachments:\n",
    "                versions_of_photo = []\n",
    "                if attachment['type'] == 'photo':\n",
    "                    photo = attachment['photo']\n",
    "                    for key, path in photo.items():\n",
    "                        if 'photo' in key:\n",
    "                            versions_of_photo.append({'size': int(key.replace('photo_', '')), 'path': path})\n",
    "\n",
    "                # находим изображение с самым большим разрешением\n",
    "                versions_of_photo = sorted(versions_of_photo, key=lambda k: k['size'], reverse=True)\n",
    "                best_photo_path = versions_of_photo[0]['path']\n",
    "\n",
    "                #post_url = 'https://vk.com/id{}?w=wall{}_{}'.format(item['from_id'], item['from_id'], item['id'])\n",
    "                images_paths.append({'post_id': item['id'], \n",
    "                                     'user_id': item['from_id'], \n",
    "                                     'image_url': best_photo_path})\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "    return images_paths\n",
    "\n",
    "\n",
    "\n",
    "def find_in_text(text, target_words=['сертификат']):\n",
    "    for target_word in target_words:\n",
    "        for line in text.split('\\n'):\n",
    "            for word in line.split(' '):\n",
    "                if len(word) > 5:\n",
    "                    word = word.lower()\n",
    "                    dist = distance(word, target_word)\n",
    "                    if dist < 4:\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_cert_bbs(image):\n",
    "    data = pytesseract.image_to_data(image, lang='rus').split('\\n')\n",
    "    all_rows = [row.split('\\t') for row in data]\n",
    "\n",
    "    columt_names = all_rows[0]\n",
    "    data_rows = all_rows[1:]\n",
    "\n",
    "    textes_data = [dict(zip(columt_names, row)) for row in data_rows]\n",
    "\n",
    "    bbs = []\n",
    "    for text_data in textes_data:\n",
    "        try:\n",
    "            if len(text_data['text'].replace(' ', '')) > 2:\n",
    "                img_w = image.size[0]\n",
    "                img_h = image.size[1]\n",
    "                bbs.append({'text': text_data['text'],\n",
    "                               'y': int(text_data['top'])/img_h, \n",
    "                               'x': int(text_data['left'])/img_w, \n",
    "                               'w': int(text_data['width'])/img_w, \n",
    "                               'h':int(text_data['height'])/img_h})\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "    return bbs\n",
    "\n",
    "\n",
    "def analyze_user(user_id, count=30, offset=0):\n",
    "    certificates_data = []\n",
    "    \n",
    "    data = {'filter': 'owner',\n",
    "            'extended': '0',\n",
    "            'owner_id': user_id, \n",
    "            'count': count, \n",
    "            'offset': offset}\n",
    "    res_posts = vk_api('wall.get', data)\n",
    "\n",
    "    try:\n",
    "        images_data = images_from_res(res_posts['response']['items'])\n",
    "\n",
    "        for image_data in images_data:\n",
    "            image_url = image_data['image_url']\n",
    "            post_id = image_data['post_id']\n",
    "            user_id = image_data['user_id']\n",
    "\n",
    "            image = download_image(image_url)\n",
    "\n",
    "            text_from_img = pytesseract.image_to_string(image, lang='rus+eng')\n",
    "\n",
    "            if find_in_text(text_from_img, target_words=target_words):\n",
    "                bbs = get_cert_bbs(image)\n",
    "\n",
    "                image_data.update({'text_from_image': text_from_img, 'bbs': bbs})\n",
    "                #save_cert(image_data)\n",
    "                \n",
    "                certificates_data.append(image_data)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        try:\n",
    "            error_msg = res_posts['error']['error_msg']\n",
    "            error_code = res_posts['error']['error_code']\n",
    "\n",
    "        except Exception:\n",
    "            error_msg = str(e)\n",
    "            error_code = None\n",
    "\n",
    "        print('error! user_id: {} msg: {}'.format(user_id, error_msg))\n",
    "        if error_code == 29:  # если достигли лимита запросов в день\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        return []\n",
    "\n",
    "    return certificates_data\n",
    "\n",
    "\n",
    "certs_of_users = []\n",
    "for index, user_id in enumerate(users_ids):\n",
    "    clear_output()\n",
    "    print(index)\n",
    "    certs_of_user = analyze_user(user_id)\n",
    "    certs_of_users.append(certs_of_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_certs = []\n",
    "for certs_of_user in certs_of_users:\n",
    "    for cert in certs_of_user:\n",
    "        cert.update({'image': download_image(cert['image_url'])})\n",
    "        all_certs.append(cert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_users_data.txt', 'w') as f:\n",
    "    f.write(json.dumps(all_certs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from flask import Flask\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///for_docker/api/db/test_certs.db'\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "db = SQLAlchemy(app)\n",
    "\n",
    "class Сertificate(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    cluster_id = db.Column(db.Integer)\n",
    "    image_url = db.Column(db.String(255))\n",
    "    text_from_image = db.Column(db.Text)\n",
    "    bbs = db.Column(db.JSON)\n",
    "    user_id = db.Column(db.Integer)\n",
    "    post_id = db.Column(db.Integer)\n",
    "    session_id = db.Column(db.Integer, default=-1)\n",
    "\n",
    "\n",
    "class Session_has_certs(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    id_session = db.Column(db.Integer)\n",
    "    id_certificate = db.Column(db.Integer)\n",
    "    __table_args__ = (db.UniqueConstraint('id_session', 'id_certificate', name='_session_certificate_uc'),)\n",
    "\n",
    "\n",
    "class Cluster(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    bbs = db.Column(db.JSON)\n",
    "    cluster_name = db.Column(db.String(100))\n",
    "\n",
    "\n",
    "class Session(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    session_name = db.Column(db.String(100))\n",
    "    status = db.Column(db.String(100))\n",
    "\n",
    "\n",
    "class Users(db.Model):\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    token = db.Column(db.String(200))\n",
    "    vk_id = db.Column(db.String(100))\n",
    "    \n",
    "#db.create_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "certificate = Сertificate(cluster_id = 7,\n",
    "                          image_url = 'aisajidf',\n",
    "                          text_from_image = 'same text',\n",
    "                          bbs = {'1': 333},\n",
    "                          user_id = 777,\n",
    "                          post_id = 111)\n",
    "\n",
    "try:\n",
    "    db.session.add(certificate)\n",
    "    db.session.commit()\n",
    "    db.session.rollback()\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Сertificate.query.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# кластеризуем все изображения и запишем результат в БД\n",
    "\n",
    "def diff_iou(bb1, bb2):\n",
    "    \"\"\"\n",
    "    bb : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x1, y1) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "    \"\"\"\n",
    "\n",
    "    if (bb1 == None) or (bb2 == None):\n",
    "        return 0.0\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    bb1 = {'x1': bb1['x'], 'x2': bb1['x'] + bb1['w'],'y1': bb1['y'],'y2': bb1['y'] + bb1['h'], 'text': bb1['text']}\n",
    "    bb2 = {'x1': bb2['x'], 'x2': bb2['x'] + bb2['w'],'y1': bb2['y'],'y2': bb2['y'] + bb2['h'], 'text': bb2['text']}\n",
    "    \n",
    "    x_left = max(bb1['x1'], bb2['x1'])\n",
    "    y_top = max(bb1['y1'], bb2['y1'])\n",
    "    x_right = min(bb1['x2'], bb2['x2'])\n",
    "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # compute the area of both AABBs\n",
    "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
    "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "    l1 = len(bb1['text'])\n",
    "    l2 = len(bb2['text'])\n",
    "    levin_dist = 1 - distance(bb1['text'], bb2['text']) / (l1 + l2)\n",
    "    iou = iou * levin_dist\n",
    "    \n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou\n",
    "\n",
    "def find_longer_dist(matrix):\n",
    "    \"\"\"\n",
    "        функция для нахождения пути (в матрице) при котором сумма всех нод данного пути будет максимальна\n",
    "    \"\"\"\n",
    "    \n",
    "    # идем горизонтальными полосами\n",
    "    non_zero_indexes = matrix[0].nonzero()[0]\n",
    "    \n",
    "    if matrix.shape[0] > 1:\n",
    "        if len(non_zero_indexes) == 0:\n",
    "            return find_longer_dist(matrix[1:])\n",
    "        else:\n",
    "            lens = []\n",
    "            for index in non_zero_indexes:\n",
    "                len_through_index = find_longer_dist(matrix[1:])\n",
    "                lens.append(len_through_index)\n",
    "            return matrix[0][index] + max(lens)\n",
    "            \n",
    "    else:\n",
    "        if len(non_zero_indexes) == 0:\n",
    "            # если в последнем слое только нули - возвращаем текущую длинну пути\n",
    "            return 0\n",
    "        else:\n",
    "            # ищем максимальную длинну в последнем слое\n",
    "            lens = []\n",
    "            for index in non_zero_indexes:\n",
    "                len_through_index = matrix[0][index]\n",
    "                lens.append(len_through_index)\n",
    "            return max(lens)\n",
    "\n",
    "def diff_bbs(bbs1, bbs2):\n",
    "    \"\"\"\n",
    "        0 - похожи, 1 - не похожи\n",
    "    \"\"\"\n",
    "    matrix = np.zeros((len(bbs1), len(bbs2)))\n",
    "    \n",
    "    for i, bb1 in enumerate(bbs1):\n",
    "        for j, bb2 in enumerate(bbs2):\n",
    "            matrix[i][j] = diff_iou(bb1, bb2)\n",
    "    \n",
    "    similarity_rows = 1 - find_longer_dist(matrix) / matrix.shape[0]\n",
    "    similarity_columnes = 1 - find_longer_dist(matrix) / matrix.shape[0]\n",
    "    similarity = max(similarity_rows, similarity_columnes)\n",
    "    return similarity\n",
    "\n",
    "def load_clusters():\n",
    "    \"\"\"\n",
    "        загрузить из БД все кластеры (их id и bbs)\n",
    "    \"\"\"\n",
    "    items = Cluster.query.all() # .order_by(Item.user_id)\n",
    "\n",
    "    clusters = []\n",
    "    for cluster in json.loads(json.dumps(items, cls=AlchemyEncoder)):\n",
    "        bbs = cluster['bbs']\n",
    "        id = cluster['id']\n",
    "        clusters.append({'id': id, 'bbs': bbs})\n",
    "\n",
    "    return clusters\n",
    "    \n",
    "\n",
    "def create_cluster(bbs):\n",
    "    \"\"\"\n",
    "        создать в БД новый кластер\n",
    "    \"\"\"\n",
    "    \n",
    "    cluster = Cluster(bbs=bbs)\n",
    "    try:\n",
    "        db.session.add(cluster)\n",
    "        db.session.commit()\n",
    "        #db.session.close()\n",
    "    except Exception as e:\n",
    "        db.session.rollback()\n",
    "        print(str(e))\n",
    "        \n",
    "    return cluster.id\n",
    "        \n",
    "def add_certificate(cert, session_id=-1):\n",
    "    \"\"\"\n",
    "        добавить сертификат в БД\n",
    "    \"\"\"\n",
    "    certificate = Сertificate.query.filter_by(image_url = cert['image_url']).first()\n",
    "    if certificate is None:\n",
    "        certificate = Сertificate(cluster_id = cert['cluster_id'],\n",
    "                                  image_url = cert['image_url'],\n",
    "                                  text_from_image = cert['text_from_image'],\n",
    "                                  bbs = cert['bbs'],\n",
    "                                  user_id = cert['user_id'],\n",
    "                                  post_id = cert['post_id'])\n",
    "\n",
    "        try:\n",
    "            db.session.add(certificate)\n",
    "            db.session.commit()\n",
    "            db.session.rollback()\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            \n",
    "    cert_id = certificate.id\n",
    "    session_has_cert = Session_has_certs(id_session=session_id, id_certificate=cert_id)\n",
    "    try:\n",
    "        db.session.add(session_has_cert)\n",
    "        db.session.commit()\n",
    "        #db.session.close()\n",
    "    except Exception as e:\n",
    "        db.session.rollback()\n",
    "        print(str(e))\n",
    "        \n",
    "    return cert_id\n",
    "    \n",
    "def update_cluster_centroids(bbs):\n",
    "    \"\"\"\n",
    "        обновить значение \"среднего\" bbs у кластера\n",
    "    \"\"\"\n",
    "    return 0\n",
    "\n",
    "def clusterize(cert_data):\n",
    "    cert_bbs = cert_data['bbs'][:20]\n",
    "    #text = cert_data['text_from_image']\n",
    "    \n",
    "    clusters = load_clusters() # [{'id': 2, 'bbs': []}, {...}, {...}]\n",
    "    \n",
    "    top_cluster_id = None\n",
    "    top_similar = -1.\n",
    "    for cluster in clusters:\n",
    "        cluster_bbs = cluster['bbs'][:20]\n",
    "        cluster_id = cluster['id']\n",
    "        \n",
    "        similarity = diff_bbs(cluster_bbs, cert_bbs)\n",
    "        \n",
    "        #print('{} => {}'.format(cluster['id'], similarity))\n",
    "        if (similarity < 0.8) and (similarity > top_similar):\n",
    "            top_similar = similarity\n",
    "            top_cluster_id = cluster_id\n",
    "    \n",
    "    if top_cluster_id is None:\n",
    "        top_cluster_id = create_cluster(bbs=cert_bbs)\n",
    "    else:\n",
    "        update_cluster_centroids(bbs=cert_bbs)\n",
    "        \n",
    "    return top_cluster_id\n",
    "\n",
    "\n",
    "\n",
    "for i, cert_data in enumerate(all_certs):\n",
    "    try:\n",
    "        cluster_id = clusterize(cert_data)\n",
    "        cert_data.update({'cluster_id': cluster_id})\n",
    "        add_certificate(cert_data)\n",
    "    except Exception as e:\n",
    "        # если новых данных нет\n",
    "        pass #print(str(e))\n",
    "    \n",
    "\n",
    "items = Cluster.query.all() # .order_by(Item.user_id)\n",
    "print('cnt of Cluster = {}'.format(len(json.loads(json.dumps(items, cls=AlchemyEncoder)))))\n",
    "\n",
    "items = Session_has_certs.query.all() # .order_by(Item.user_id)\n",
    "print('cnt of Session_has_certs = {}'.format(len(json.loads(json.dumps(items, cls=AlchemyEncoder)))))\n",
    "\n",
    "items = Сertificate.query.all() # .order_by(Item.user_id)\n",
    "print('cnt of Сertificate = {}'.format(len(json.loads(json.dumps(items, cls=AlchemyEncoder)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze_script import *\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#users_ids = get_all_members('pumptraffic')\n",
    "users_ids = [file_name.split('.')[0] for file_name in os.listdir('saved_data')]\n",
    "print('users len = ', len(users_ids))\n",
    "print('users loaded')\n",
    "\n",
    "certs_of_users = []\n",
    "for index, user_id in enumerate(users_ids):\n",
    "    \n",
    "        clear_output()\n",
    "        print('user ind', index)\n",
    "        certs_of_user = analyze_user(user_id, target_words=['диплом', \n",
    "                                                            'сертификат', \n",
    "                                                            'лицензия', \n",
    "                                                            'certified', \n",
    "                                                            'specialist', \n",
    "                                                            'специалист', \n",
    "                                                            'эксперт'])\n",
    "\n",
    "        for cert_data in certs_of_user:\n",
    "            try:\n",
    "                cluster_id = clusterize(cert_data)\n",
    "                cert_data.update({'cluster_id': cluster_id})\n",
    "                add_certificate(cert_data)\n",
    "\n",
    "            except Exception as e:\n",
    "                # если новых данных нет\n",
    "                print(str(e))\n",
    "    \n",
    "    \n",
    "\n",
    "items = Cluster.query.all() # .order_by(Item.user_id)\n",
    "print('cnt of Cluster = {}'.format(len(json.loads(json.dumps(items, cls=AlchemyEncoder)))))\n",
    "\n",
    "items = Session_has_certs.query.all() # .order_by(Item.user_id)\n",
    "print('cnt of Session_has_certs = {}'.format(len(json.loads(json.dumps(items, cls=AlchemyEncoder)))))\n",
    "\n",
    "items = Сertificate.query.all() # .order_by(Item.user_id)\n",
    "print('cnt of Сertificate = {}'.format(len(json.loads(json.dumps(items, cls=AlchemyEncoder)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "items = Session_has_certs.query.all() # .order_by(Item.user_id)\n",
    "{id_cert: id_json.loads(json.dumps(items, cls=AlchemyEncoder))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_alias = aliased(User, name='user2')\n",
    "def get_certs_by_cluster(id):\n",
    "    items = Сertificate.query.filter_by(cluster_id = id).all()\n",
    "    certs = json.loads(json.dumps(items, cls=AlchemyEncoder))\n",
    "    return certs\n",
    "\n",
    "len(get_certs_by_cluster(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = Сertificate.query.all()\n",
    "certs = json.loads(json.dumps(items, cls=AlchemyEncoder))\n",
    "\n",
    "len(certs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = Cluster.query.all()\n",
    "clusters = json.loads(json.dumps(items, cls=AlchemyEncoder))\n",
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clusters = []\n",
    "for cluster in clusters:\n",
    "    cluster_id = cluster['id']\n",
    "    cluster_name = 'кластер #{}'.format(cluster_id) # cluster['cluster_name']\n",
    "    certs = get_certs_by_cluster(cluster_id)\n",
    "    \n",
    "    current_cluster = []\n",
    "    for cert in certs:\n",
    "        current_cluster.append({\n",
    "                          'id': cert['id'], \n",
    "                          'bbs': cert['bbs'], \n",
    "                          'image_url': cert['image_url'], \n",
    "                          'post_id': cert['post_id'], \n",
    "                          'user_id': cert['user_id'],\n",
    "                         })\n",
    "        \n",
    "    all_clusters.append({'cluster_id': cluster_id, 'cluster_name': cluster_name, 'certificates': current_cluster})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = []\n",
    "for i in range (1, 50):\n",
    "    certs = get_certs_by_cluster(i)\n",
    "    current_cluster = []\n",
    "    \n",
    "    for cert in certs:\n",
    "        current_cluster.append({'id': cert['id'], \n",
    "                                'bbs': cert['bbs'], \n",
    "                                'image_url': cert['image_url'], \n",
    "                                'post_id': cert['post_id'], \n",
    "                                'user_id': cert['user_id']\n",
    "                               })\n",
    "    if len(current_cluster) > 1:\n",
    "        response.append({'cluster_id': i, 'cluster_name': 'кластер #{}'.format(i), 'certificates': current_cluster})\n",
    "        \n",
    "    '''if len(response) == 14:\n",
    "        break'''\n",
    "        \n",
    "len(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_res.json', 'w') as f:\n",
    "    f.write(json.dumps(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "def download_image(image_url):\n",
    "    res = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(res.content))\n",
    "    return image\n",
    "cluster_ind = 0\n",
    "\n",
    "max_posts_in_cluster = max([len(current_cluster['certificates']) for current_cluster in response])\n",
    "\n",
    "fig, axis = plt.subplots(len(response), max_posts_in_cluster, figsize=(10, 10*((len(response)//max_posts_in_cluster)+1)))\n",
    "\n",
    "for i in range(len(response)):\n",
    "    for j in range(len(response[i]['certificates'])):\n",
    "        img_url = response[i]['certificates'][j]['image_url']\n",
    "        img = download_image(img_url)\n",
    "        \n",
    "        axis[i][j].imshow(img)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Сertificate.query.filter_by(cluster_id = 4).first().from_id_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def diff_bbs(bbs1, bbs2):\n",
    "    \"\"\"\n",
    "        0 - похожи, 1 - не похожи\n",
    "    \"\"\"\n",
    "    matrix = np.zeros((len(bbs1), len(bbs2)))\n",
    "    \n",
    "    for i, bb1 in enumerate(bbs1):\n",
    "        for j, bb2 in enumerate(bbs2):\n",
    "            matrix[i][j] = diff_iou(bb1, bb2)\n",
    "    \n",
    "    similarity_rows = 1 - find_longer_dist(matrix) / matrix.shape[0]\n",
    "    similarity_columnes = 1 - find_longer_dist(matrix) / matrix.shape[0]\n",
    "    similarity = max(similarity_rows, similarity_columnes)\n",
    "    return similarity, matrix\n",
    "\n",
    "bbs1 = all_certs[0]['bbs']\n",
    "bbs2 = all_certs[2]['bbs']\n",
    "\n",
    "diff_bbs(bbs1, bbs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def load_images_data():\n",
    "    items = Сertificate.query.all() # .order_by(Item.user_id)\n",
    "\n",
    "    certificates = defaultdict(list)\n",
    "    for cert_data in all_certs_data: #json.loads(json.dumps(items, cls=AlchemyEncoder)):\n",
    "        image = cert_data['image']\n",
    "        cluster_id = cert_data['cluster_id']\n",
    "        \n",
    "        certificates[cluster_id].append(image)\n",
    "    \n",
    "    return dict(certificates)\n",
    "\n",
    "clusters = load_images_data()\n",
    "\n",
    "max_posts_in_cluster = max([len(cluster_posts) for _, cluster_posts in clusters.items()])\n",
    "print(len(clusters))\n",
    "print(max_posts_in_cluster)\n",
    "fig, axis = plt.subplots(len(clusters), max_posts_in_cluster, figsize=(10, 10*((len(clusters)//max_posts_in_cluster)+1)))\n",
    "\n",
    "for cluster_id, (_, cluster_posts) in enumerate(clusters.items()):\n",
    "    for index_post, cluster_post in enumerate(cluster_posts):\n",
    "        image = cluster_post # image cert_img\n",
    "        if image == None:\n",
    "            continue\n",
    "\n",
    "        axis[cluster_id][index_post].imshow(image)\n",
    "        #axis[cluster_id][index_post].annotate(cluster_post['post_url'].split('wall')[1], xy=(0.5, 10), xytext=(0, 10))\n",
    "        \n",
    "        #cert_coords = cluster_post['cert_coords']\n",
    "        #rect = patches.Rectangle((coords['x']*image.size[0],coords['y'])*image.size[1],coords['w']*image.size[0],coords['h']*image.size[1],linewidth=1,edgecolor='r',facecolor='none')\n",
    "        #axis[cluster_id][index_post].add_patch(rect)\n",
    "        \n",
    "plt.savefig('clusters_of_users.png')\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
